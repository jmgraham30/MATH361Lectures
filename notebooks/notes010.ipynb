{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "using DrWatson;\n",
    "@quickactivate \"MATH361Lectures\"\n",
    "using LinearAlgebra, Latexify;\n",
    "import MATH361Lectures;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Matrix Norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Recall that a system of linear equations may be written as $Ax=b$, where $A$ is an $m\\times n$ coefficient matrix, $x$ is an $n\\times 1$ column vector of unknowns, and $b$ is an $m\\times 1$ column vector. In order to study the conditioning of a linear system or the stability of a numerical method for solving a linear system, we need to be able to measure the effects of small perturbations (say due to round-off error) to the data of the problem, that is, the matrix $A$ and vectors $x$ and $b$. Norms are perfect tools for this, wouldn't it be great if we could extend our definition of norms on vectors to norms on matrices? This is exactly what we will do in this lecture.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It's important to note that there are a few different approaches commonly taken to define norms on matrices. One of the most common approaches arises by viewing a matrix as a function, specifically, we think of a matrix $A$ as a linear transformation on a vector space. This leads to the idea of a matrix norm induced by a vector norm.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Induced Matrix Norms\n",
    "\n",
    "Let $A$ be an $m\\times n$ matrix and let $\\|\\cdot\\|_{p}$ (typically $p$ will be 1, 2, or $\\infty$) be a norm on $\\mathbb{R}^{m}$ (we will also let $\\|\\cdot\\|_{p}$ denote a norm on $\\mathbb{R}^{n}$), then the matrix norm $\\|\\cdot \\|$ induced by $\\|\\cdot\\|_{p}$ is defined as follows:\n",
    "\n",
    "$$\\|A\\| = \\max_{v \\neq 0}\\frac{\\|Av\\|_{p}}{\\|v\\|_{p}} = \\max_{\\|v\\|_{p}=1}\\|Av\\|_{p}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is an abstract definition and can take some time to get a feel for. It turns out that it's possible to write down a very concrete formula for the matrix norm induced by the 1 vector norm and the $\\infty$ vector norm. We will come to that soon. First, let's prove that our definition of an induced norm does in fact lead to an object that satisfies the conditions necessary to be a norm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In what follows, we will start to use a common abuse of notation. That is, we will use the symbol $\\| \\cdot \\|$ to denote **both** a matrix norm **and** a vector norm. For example, we will now simply write\n",
    "\n",
    "$$\\|A\\| = \\max_{v \\neq 0}\\frac{\\|Av\\|}{\\|v\\|} = \\max_{\\|v\\|=1}\\|Av\\|.$$\n",
    "\n",
    "We will use context to determine if $\\| \\cdot \\|$ is referring to a vector norm or a matrix norm. For example, if $A$ is a matrix, then $\\|A\\|$ clearly refers to a matrix norm while if $v$ is a vector $\\|v\\|$ clearly refers to a vector norm. Remeber that if $A$ is a matrix and $v$ is a vector, then $Av$ is a vector. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Theorem** The definition\n",
    "$$\\|A\\| = \\max_{v \\neq 0}\\frac{\\|Av\\|}{\\|v\\|} = \\max_{\\|v\\|=1}\\|Av\\|,$$\n",
    "defines a norm. \n",
    "\n",
    "Let's derive a proof for this theorem. Recall the conditions necessary to be a norm:\n",
    "\n",
    "A norm is a real valued function that satisfies\n",
    "\n",
    "  1) $\\|A\\| \\geq 0$, \n",
    "  \n",
    "  2) $\\|A\\| = 0$ if and only if $A = 0$, \n",
    "  \n",
    "  3) $\\|\\alpha A\\| = |\\alpha| \\|A\\|$ whenever $\\alpha \\in R$, and\n",
    "  \n",
    "  4) the triangle inequality $\\|A + B\\| \\leq \\|A\\| + \\|B\\|$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Condition 1) is obvious from the defintion of induced norm. Let's check condition 2), suppose that $\\|A\\| = 0$, then by definition $\\max_{\\|v\\|=1}\\|Av\\|=0$. Thus, if $v$ is **any** unit vector, we must have that $0 \\leq \\|Av\\| \\leq 0$. This is **only possible** if $Av = 0$ for every unit vector $v$. This in turn implies that $Av = 0$ for **every** vector $v$. (If it seems like we skipped a step here don't worry, you'll have a chance to fill in the missing step in the homework.)\n",
    "\n",
    "Condition 3) is also very easy since $\\|\\alpha A\\| = \\max_{\\|v\\|=1}\\|\\alpha Av\\|$, but $\\|\\alpha Av\\|=|\\alpha|\\| Av\\|$ independent of $v$ and therefore $\\|\\alpha A\\| = |\\alpha| \\|A\\|$.\n",
    "\n",
    "Finally, we need to check that the triangle inequality is satisfied. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let $A$ and $B$ be two matrices of the same size. Notice that for any unit vector $v$, we have $\\|(A+B)v\\| = \\|Av + Bv\\| \\leq \\|Av\\| + \\|Bv\\|$ and thus\n",
    "\n",
    "$$\\|A + B\\| = \\max_{\\|v\\|=1}\\|(A+B)v\\| \\leq \\max_{\\|v\\|=1}\\|Av\\| + \\max_{\\|v\\|=1}\\|Bv\\| = \\|A\\| + \\|B \\|.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Thus, we have shown that the induced norm is indeed a norm (on matrices). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Expressions for the Induced norm when $p=1$ or $p=\\infty$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Induced 1-norm\n",
    "\n",
    "The matrix norm induced by the vector 1-norm can be computed with the following formula:\n",
    "\n",
    "$$\\|A\\|_{1} = \\max_{1\\leq j \\leq n}\\sum_{i=1}^{m}|a_{ij}|$$\n",
    "\n",
    "Maximum **column** sum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example:** Consider the matrix $A$ defined by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{equation}\n",
       "\\left[\n",
       "\\begin{array}{cccc}\n",
       "-1.0 & 2.0 & 1.0 & 4.0 \\\\\n",
       "-3.0 & 2.0 & 1.0 & 1.0 \\\\\n",
       "-1.0 & 0.0 & 1.0 & -2.0 \\\\\n",
       "-4.0 & 1.0 & -2.0 & -1.0 \\\\\n",
       "\\end{array}\n",
       "\\right]\n",
       "\\end{equation}\n"
      ],
      "text/plain": [
       "L\"\\begin{equation}\n",
       "\\left[\n",
       "\\begin{array}{cccc}\n",
       "-1.0 & 2.0 & 1.0 & 4.0 \\\\\n",
       "-3.0 & 2.0 & 1.0 & 1.0 \\\\\n",
       "-1.0 & 0.0 & 1.0 & -2.0 \\\\\n",
       "-4.0 & 1.0 & -2.0 & -1.0 \\\\\n",
       "\\end{array}\n",
       "\\right]\n",
       "\\end{equation}\n",
       "\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [-1.0 2.0 1.0 4.0;-3.0 2.0 1.0 1.0;-1.0 0.0 1.0 -2.0;-4.0 1.0 -2.0 -1.0];\n",
    "latexify(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can add up the absolute values of all the entries in each **column**:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "|a_{11}| + |a_{21}| + |a_{31}| + |a_{41}| &= |-1| + |-3| + |-1| + |-4| = 9 \\\\\n",
    "|a_{12}| + |a_{22}| + |a_{32}| + |a_{42}| &= |2| + |2| + |0| + |1| = 5 \\\\\n",
    "|a_{13}| + |a_{23}| + |a_{33}| + |a_{43}| &= |1| + |1| + |1| + |-2| = 5 \\\\\n",
    "|a_{14}| + |a_{24}| + |a_{34}| + |a_{44}| &= |4| + |1| + |-2| + |-1| = 8\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Thus, $\\|A\\|_{1} = 9$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Derivation of the formula for matrix 1-norm:** This involves two steps, first we show that if $v$ is a unit vector with respect to the 1-norm, then $\\|Av\\| \\leq \\max_{1\\leq j \\leq n}\\sum_{i=1}^{m}|a_{ij}|$, this then implies that $\\|A\\| = \\max_{\\|v\\|_{1}=1}\\|Av\\| \\leq \\max_{1\\leq j \\leq n}\\sum_{i=1}^{m}|a_{ij}|$. \n",
    "\n",
    "In our second step, we will show that there is a vector $v$ such that $\\|v\\|_{1} = 1$ and $\\|Av\\|_{1} = \\max_{1\\leq j \\leq n}\\sum_{i=1}^{m}|a_{ij}|$. This means that we can find a vector in which equality is achieved for the inequality $\\max_{\\|v\\|_{1}=1}\\|Av\\| \\leq \\max_{1\\leq j \\leq n}\\sum_{i=1}^{m}|a_{ij}|$. \n",
    "\n",
    "These facts taken together prove that $\\|A\\|_{1} = \\max_{1\\leq j \\leq n}\\sum_{i=1}^{m}|a_{ij}|$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let $v$ be a vector such that $\\|v\\|_{1} = 1$, that is, $|v_{1}|+|v_{2}|+\\cdots |v_{n}| = 1$. Then,\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\|Av\\|_{1} &= \\sum_{i=1}^{m}\\left|\\sum_{j=1}^{n}a_{ij}v_{j} \\right|\n",
    "\\leq \\sum_{i=1}^{m}\\sum_{j=1}^{n}|a_{ij}||v_{j}| \\\\\n",
    "&= \\sum_{j=1}^{n}\\left[\\sum_{i=1}^{m}|a_{ij}|\\right]|v_{j}| \\leq \\max_{1\\leq j \\leq n}\\left\\{\\sum_{i=1}^{m}|a_{ij}| \\right\\}\\sum_{j=1}^{n}|v_{j}| \\\\\n",
    "&=\\max_{1\\leq j \\leq n}\\left\\{\\sum_{i=1}^{m}|a_{ij}| \\right\\}, \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "this last equality holds since $\\sum_{j=1}^{n}|v_{j}|=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now suppose that for the matrix $A$, we have that $\\max_{1\\leq j \\leq n}\\left\\{\\sum_{i=1}^{m}|a_{ij}| \\right\\} = \\sum_{i=1}^{m}|a_{ik}|$. That is, the maximum column sum of $A$ occurs for column $k$. Set $v=e_{k}$, where $e_{k}$ is the vector with $1$ in the $k$-th entry and zero elsewhere. Apparently $\\|e_{k}\\|_{1} = 1$ and $\\|Ae_{k}|_{1} = \\sum_{i=1}^{m}|a_{ik}| = \\max_{1\\leq j \\leq n}\\left\\{\\sum_{i=1}^{m}|a_{ij}| \\right\\}$. Thus, we have discovered a unit vector such that equality is achieved in the inequality $\\max_{\\|v\\|_{1}=1}\\|Av\\| \\leq \\max_{1\\leq j \\leq n}\\sum_{i=1}^{m}|a_{ij}|$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Induced $\\infty$-norm\n",
    "\n",
    "The matrix norm induced by the vector $\\infty$-norm can be computed with the following formula:\n",
    "\n",
    "$$\\|A\\|_{\\infty} = \\max_{1\\leq i \\leq m}\\sum_{i=1}^{n}|a_{ij}|$$\n",
    "\n",
    "Maximum **row** sum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example:** Consider again the earlier matrix $A$ defined by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{equation}\n",
       "\\left[\n",
       "\\begin{array}{cccc}\n",
       "-1.0 & 2.0 & 1.0 & 4.0 \\\\\n",
       "-3.0 & 2.0 & 1.0 & 1.0 \\\\\n",
       "-1.0 & 0.0 & 1.0 & -2.0 \\\\\n",
       "-4.0 & 1.0 & -2.0 & -1.0 \\\\\n",
       "\\end{array}\n",
       "\\right]\n",
       "\\end{equation}\n"
      ],
      "text/plain": [
       "L\"\\begin{equation}\n",
       "\\left[\n",
       "\\begin{array}{cccc}\n",
       "-1.0 & 2.0 & 1.0 & 4.0 \\\\\n",
       "-3.0 & 2.0 & 1.0 & 1.0 \\\\\n",
       "-1.0 & 0.0 & 1.0 & -2.0 \\\\\n",
       "-4.0 & 1.0 & -2.0 & -1.0 \\\\\n",
       "\\end{array}\n",
       "\\right]\n",
       "\\end{equation}\n",
       "\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [-1.0 2.0 1.0 4.0;-3.0 2.0 1.0 1.0;-1.0 0.0 1.0 -2.0;-4.0 1.0 -2.0 -1.0];\n",
    "latexify(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can add up the absolute values of all the entries in each **row**:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "|a_{11}| + |a_{12}| + |a_{13}| + |a_{13}| &= |-1| + |2| + |1| + |4| = 8 \\\\\n",
    "|a_{21}| + |a_{22}| + |a_{23}| + |a_{24}| &= |-3| + |2| + |1| + |1| = 7 \\\\\n",
    "|a_{31}| + |a_{32}| + |a_{33}| + |a_{32}| &= |-1| + |0| + |1| + |-2| = 4 \\\\\n",
    "|a_{41}| + |a_{42}| + |a_{43}| + |a_{44}| &= |-4| + |1| + |-2| + |-1| = 8\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Thus, $\\|A\\|_{1} = 8$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Derivation of the formula for matrix $\\infty$-norm:** This is left as a homework exercise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "An induced matrix norm satisfies some important and useful properties:\n",
    "\n",
    "Let $\\|\\cdot \\|_{\\text{matrix}}$ be a matrix norm induced by a vector norm $\\|\\cdot\\|_{\\text{vector}}$. Then for all matrices and vectors of compatible size, \n",
    "\n",
    "$$\\|Ax\\|_{\\text{vector}} \\leq \\|A \\|_{\\text{matrix}} \\|x\\|_{\\text{vector}},$$\n",
    "$$\\|AB \\|_{\\text{matrix}} \\leq \\|A \\|_{\\text{matrix}}\\|B \\|_{\\text{matrix}},$$\n",
    "$$\\|A^{k} \\|_{\\text{matrix}} \\leq \\|A \\|_{\\text{matrix}}^{k},$$ whenever $k$ is a nonnegative integer and $A$ is a square matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Using our previously mentioned minor abuse of notation, we can write the last statements as\n",
    "\n",
    "  1) $\\|Ax\\| \\leq \\|A \\| \\|x\\|,$\n",
    "  \n",
    "  2) $\\|AB \\| \\leq \\|A \\|\\|B \\|,$\n",
    "  \n",
    "  3) $\\|A^{k} \\| \\leq \\|A \\|^{k},$ whenever $k$ is a nonnegative integer and $A$ is a square matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will prove properties 1) and 3) and leave the proof of property 2) as a homework exericse. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To prove property 1) note that for **any** nonzero vector $x$, we have that \n",
    "\n",
    "$$\\frac{\\|Ax\\|}{\\|x\\|} \\leq \\max_{x \\neq 0}\\frac{\\|Ax\\|}{\\|x\\|} = \\|A\\|$$\n",
    "\n",
    "and thus $\\|Ax\\| \\leq \\|A\\|\\|x\\|$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To prove property 3) we will use property 2) together with [mathematical induction](https://en.wikipedia.org/wiki/Mathematical_induction). We begin with the base case where $k=1$, then it is trivially true that $\\|A^{1}\\| \\leq \\|A\\|^{1}$. The case when $k=2$ is almost as easy, just take $A=B$ in property 2) since then $\\|A^2\\| = \\|AA\\| \\leq \\|A\\|\\|A\\| = \\|A\\|^2$.  \n",
    "\n",
    "For the induction step, suppose that $\\|A^k\\| \\leq \\|A\\|^k$ for all integers $1\\leq k \\leq N$ and consider $\\|A^{N+1}\\|$, we have\n",
    "\n",
    "$$\\|A^{N+1}\\| = \\|A^{N}A\\| \\leq \\|A^{N}\\|\\|A\\|$$\n",
    "\n",
    "where we used property 2) to obtain the last inequality. Now, by the induction hypothesis we have that $\\|A^{N}\\|\\leq \\|A\\|^{N}$ and thus\n",
    "\n",
    "$$\\|A^{N+1}\\| \\leq \\|A\\|^{N}\\|A\\| = \\|A\\|^{N+1}.$$\n",
    "\n",
    "The principle of mathematical induction then gives that $\\|A^{k} \\| \\leq \\|A \\|^{k},$ whenever $k$ is a nonnegative integer and $A$ is a square matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Induced 2-norm\n",
    "\n",
    "You're probably wondering (and rightly so) if there is a formula for the induced matrix 2-norm analogous to those for the 1 and $\\infty$ norms? Unfotunately this is not the case, but the induced matrix 2-norm can be characterized in terms of other concepts familiar from linear algera. Specifically, \n",
    "\n",
    "$$\n",
    "\\|A\\|_{2} = \\max \\left\\{\\sqrt{|\\lambda|}: \\text{$\\lambda$ is an eigenvalue of $A^{T}A$}\\right\\}\n",
    "$$\n",
    "\n",
    "We will return to this idea a bit later in the course. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Frobenius norm\n",
    "\n",
    "Not all matrix norms arise as an matrix norm induced by a vector norm. The most important example is the so-call [Frobenius norm](https://en.wikipedia.org/wiki/Matrix_norm#Frobenius_norm) which is defined  by the formula\n",
    "\n",
    "$$\\|A\\|_{\\text{Frobenius}} = \\sqrt{\\sum_{i=1}^{m}\\sum_{j=1}^{n}|a_{ij}|^2}.$$\n",
    "\n",
    "We may also return to the Frobenius norm later in the course if time permits. For now, let's see how we can use Julia to compute some matrix norms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Computing matrix norms in Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In Julia, we can use the ```opnorm``` function to compute the induced matrix norm. For example, consider again the matrix $A$ defined by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{equation}\n",
       "\\left[\n",
       "\\begin{array}{cccc}\n",
       "-1.0 & 2.0 & 1.0 & 4.0 \\\\\n",
       "-3.0 & 2.0 & 1.0 & 1.0 \\\\\n",
       "-1.0 & 0.0 & 1.0 & -2.0 \\\\\n",
       "-4.0 & 1.0 & -2.0 & -1.0 \\\\\n",
       "\\end{array}\n",
       "\\right]\n",
       "\\end{equation}\n"
      ],
      "text/plain": [
       "L\"\\begin{equation}\n",
       "\\left[\n",
       "\\begin{array}{cccc}\n",
       "-1.0 & 2.0 & 1.0 & 4.0 \\\\\n",
       "-3.0 & 2.0 & 1.0 & 1.0 \\\\\n",
       "-1.0 & 0.0 & 1.0 & -2.0 \\\\\n",
       "-4.0 & 1.0 & -2.0 & -1.0 \\\\\n",
       "\\end{array}\n",
       "\\right]\n",
       "\\end{equation}\n",
       "\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [-1.0 2.0 1.0 4.0;-3.0 2.0 1.0 1.0;-1.0 0.0 1.0 -2.0;-4.0 1.0 -2.0 -1.0];\n",
    "latexify(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 1-norm of A is 9.0\n",
      "The infinity-norm of A is 8.0\n",
      "The 2-norm of A is 5.928835216555143\n"
     ]
    }
   ],
   "source": [
    "println(\"The 1-norm of A is \", opnorm(A,1))\n",
    "println(\"The infinity-norm of A is \", opnorm(A,Inf))\n",
    "println(\"The 2-norm of A is \", opnorm(A,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As an application of using Julia to compute induced matrix norms, let's confirm the characterisation of the induced 2-norm\n",
    "\n",
    "$$\n",
    "\\|A\\|_{2} = \\max \\left\\{\\sqrt{|\\lambda|}: \\text{$\\lambda$ is an eigenvalue of $A^{T}A$}\\right\\}.\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "First, we compute $A^T A$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×4 Matrix{Float64}:\n",
       "  27.0  -12.0  3.0  -1.0\n",
       " -12.0    9.0  2.0   9.0\n",
       "   3.0    2.0  7.0   5.0\n",
       "  -1.0    9.0  5.0  22.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATA = transpose(A)*A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now let's obtain the eigenvalues of this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       "  0.0035652176400028076\n",
       "  5.175144015430741\n",
       " 24.67020374186479\n",
       " 35.15108702506446"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATA_eigs = eigvals(ATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Then we compute the square roots of these eigenvalues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       " 0.05970944347423452\n",
       " 2.2748942866495447\n",
       " 4.966910885234885\n",
       " 5.928835216555142"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATA_eigs_sqrt = sqrt.(ATA_eigs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Then we find the maximum one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.928835216555142"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_ATA_eigs_sqrt = maximum(ATA_eigs_sqrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This should be exactly the same (perhaps modulo some rounding) as the induced 2-norm which again is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.928835216555143"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_2 = opnorm(A,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_ATA_eigs_sqrt ≈ A_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How do we compute the Frobenius norm in Julia? Simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.06225774829855"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_F = norm(A,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can check this by adding up the square of each entry of $A$ and then taking the square root:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.06225774829855"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_ss = sqrt(sum(A.^2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Later in the course we may present further discussion on norms and matrix norms in particular. For now, let's move on to use the concpets and tools we have developed to study issues of conditioning and stability related to the numerical solution of systems of linear equations. \n",
    "\n",
    "In preparation for the next lecture, you are encouraged to watch [this lecture video](https://www.youtube.com/watch?v=3Fv_hdfPJ6A&list=PLvUvOH0OYx3BcZivtXMIwP6hKoYv0YvGn&index=12) on conditioning of linear systems. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
