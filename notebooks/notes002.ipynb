{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "using DrWatson;\n",
    "@quickactivate \"NumericalAnalysis\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Floating Point Numbers\n",
    "\n",
    "In reading these notes, it is helpful to also watch and refer to [this video](https://www.youtube.com/watch?v=97Gb9TS3MJs) on floating point numbers and roundoff error. A really great video on floating point arithmetic in Julia may be found [here](https://www.youtube.com/watch?v=fL8vYG69EhE&t=14s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The set of all real numbers $\\mathbb{R}$ is continuous and unbounded. Due to considerations of memory and efficiency, it is not practical to store the exact value of each real number when carrying out numerical computations on a machine. Thus, we construct a discrete, finite subset $\\mathbb{P}$ of $\\mathbb{R}$, called **floating point numbers**[^1], and a function $\\text{fl}:\\mathbb{R} \\rightarrow \\mathbb{P}$ called **rounding** that sends each real number to it's floating point approximation. (In fact, $\\mathbb{P}$ will be a subset of the set of all rational numbers $\\mathbb{Q}$.) Then, we approximate values and operations in $\\mathbb{R}$ with values and operations in $\\mathbb{P}$. Thus, we will discretize  $\\mathbb{R}$, and since in general $|\\text{fl}(x) - x| > 0$ for $x\\in \\mathbb{R}$, this produces a type of discretization error called **roundoff error**. It is important for us to learn to assess and control for roundoff error. \n",
    "\n",
    "[^1]: Note that the textbook uses $\\mathbb{F}$ to denote the set of floating point numbers. Since $\\mathbb{F}$ is often used to denote a set with the algebraic structure of a field, and floating point numbers do not form a field, we prefer to use $\\mathbb{P}$ instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Rounding and roundoff error can lead to some surprising consequences. In order to illustrate what can happen as a result of roundoff we will look at a over-simplified toy model. Suppose for the sake of simplicity that we round off all results of arithmetic to three significant digits. Thus a number such as $1.234$ would become $1.23$ after rounding, while $2.345$ would become $2.35$. In the following calculation, we use $=$ to denote the result of an exact calculation and $\\approx$ to denote the result of a calculation after rounding. Then\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "&(2.31 + 0.00312) + 0.00312 = 2.31312 + 0.00312 \\\\\n",
    "&\\approx 2.31 + 0.0312 = 2.31312 \\approx 2.31\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "while \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "&2.31 + (0.00312 + 0.00312) = 2.31 + 0.00624 \\\\\n",
    "&\\approx 2.31 + 0.01 = 2.32 \\approx 2.32\n",
    "\\end{align*}\n",
    "$$\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " \n",
    "Thus, $(2.31 + 0.00312) + 0.00312$ is rounded to $2.31$ while $2.31 + (0.00312 + 0.00312)$ is rounded to $2.32$. Rounding, that is, discretizing $\\mathbb{R}$ has resulted in the loss of the associative property of addition that is satisfied by abstract real number arithmetic.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The goal of these notes is to explain in detail the discretization $\\text{fl}:\\mathbb{R} \\rightarrow \\mathbb{P}$ and explore those aspects and consequences of this discretization that are most relevant in the context of numerical analysis. Before we construct the discretization $\\text{fl}:\\mathbb{R} \\rightarrow \\mathbb{P}$, it is helpful to reconsider $\\mathbb{R}$ from a perspective that may be unfamiliar, that is, we consider the binary rather than decimal representation of real numbers.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Binary Representation of Real Numbers\n",
    "\n",
    "From calculus and other math courses you are likely used to dealing with real numbers (*i.e.*, elements of $\\mathbb{R}$) as decimal numbers. That is, we write a positive element $x \\in \\mathbb{R}$ as\n",
    "\n",
    "\n",
    "$$x = a_{N}10^N + a_{N-1}10^{N-1} + \\cdots + a_{1} 10^1 + a_{0}10^0 + a_{-1}10^{-1} + a_{-2}10^{-2} + \\cdots ,$$\n",
    "\n",
    "where $N \\in \\mathbb{Z}$, each $a_{i}\\in \\{0,1,0,2,3,4,5,6,7,8,9\\}$ with $a_{N}\\neq 0$, and the expression may contain an infinite number of terms with negative powers of 10. Of course $0$ simply has all coefficents equal to zero, and to get negative real numbers we just \"change the sign\" of a positive real number by multiplying by $-1$. As a simple example,  \n",
    "\n",
    "$$3.14 = 3 \\times 10^1 + 1 \\times 10^{-1} + 4 \\times 10^{-2}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Observe that we can write our general expression more succinctly as\n",
    "\n",
    "$$x = \\sum_{k=-\\infty}^{N} a_{k}10^k,$$ \n",
    "\n",
    "\n",
    "or even \n",
    "\n",
    "$$x = \\pm a \\left(1 + \\sum_{j=1}^{\\infty}a_{j}10^{-j} \\right)10^{N} = \\pm a (1 + f)10^{N},$$\n",
    "\n",
    "\n",
    "where $f = \\sum_{j=1}^{\\infty}a_{j}10^{-j}$, with $a\\in \\{1,2,3,4,5,6,7,8,9\\}$, and $a_{j}\\in \\{0,1,2,3,4,5,6,7,8,9\\}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example,\n",
    "\n",
    "$$24.6 = 2\\times 10^1 + 4 \\times 10^0 + 6 \\times 10^{-1} = +2(1 + 2 \\times 10^{-1} + 3 \\times 10^{-2})10^{1}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's use Julia to confirm our result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 2*(1 + 2*10.0^-1 + 3*10.0^-2)*10.0^1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Take note that $24.6$ is a rational number with a finite decimal expansion. On the other hand, a number such as $\\frac{1}{3}$ has an inifite but repeating decimal expansion and there are even irrational numbers (*e.g.*, $\\sqrt{2}$)  that have an infinite and nonrepeating decimal expansion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Decimal expansion uses base 10 in the sense that every number is represented as a (potentially infinite) sum of products of powers of 10 by elements from $\\{0,1,2,3,4,5,6,7,8,9\\}$. This is a choice that, while familiar is arbitrary. As just one alternative, one may instead represent real numbers in base 2, that is, as a (potentially infinite) sum of products of powers of 2 by elements from $\\{0,1\\}$. In this case, we can write a real number as\n",
    "\n",
    "\n",
    "$$x = \\pm (1 + f)2^{N},$$\n",
    "\n",
    "where $f = \\sum_{j=1}^{\\infty}a_{j}2^{-j}$, with $a_{j}\\in \\{0,1\\}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example,\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    " 17.25 &= 1\\times 2^4 + 0 \\times 2^3 + 0\\times 2^2 + 0\\times 2^1 + 1\\times 2^0 + 0 \\times 2^{-1} + 1 \\times 2^{-2} \\\\\n",
    " &= +(1 + 0 \\times 2^{-1} + 0\\times 2^{-2} + 0\\times 2^{-3} + 1\\times 2^{-4} + 0 \\times 2^{-5} + 1 \\times 2^{-6})2^{4} \\\\\n",
    " &= +(1 + f)2^{4},\n",
    "\\end{align*}\n",
    "$$\n",
    "where $f=0 \\times 2^{-1} + 0\\times 2^{-2} + 0\\times 2^{-3} + 1\\times 2^{-4} + 0 \\times 2^{-5} + 1 \\times 2^{-6}$. \n",
    "\n",
    "Again we can confirm this result in Julia, this time using a little bit of code cleverness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.25"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = [0,0,0,1,0,1]; # the coefficients of f\n",
    "p = -1:-1:-6; # the relevant powers of 2 in f\n",
    "t = 2.0.^p; # raise 2 to the relevant powers\n",
    "f = sum(c.*t); # compute f\n",
    "x = (1 + f)*2.0^4 # compute x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now we will look at an example that illusrates the general method for finding the binary representation of a decimal number. Consider $3.1$. It is probably easiest to break this up into two steps. Write $3.1 = 3.0 + 0.1$ and find the binary expansions for the integer part, *i.e.*, $3$ and the fractional part, *i.e*, $0.1$ separately.  The integer part is straightforward:\n",
    "$$\n",
    "\\begin{align*}\n",
    "3 &= 2 + 1 \\\\\n",
    "&= 1\\times 2^1 + 1 \\times 2^{0}. \n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To find the binary expansion of the fractional part $0.1$ we proceed by \"repeated multiplication by 2\":\n",
    "$$\n",
    "\\begin{align*}\n",
    "0.1 \\times 2 &= \\color{red}{0}.2 \\rightarrow \\color{red}{0} \\\\\n",
    "0.2 \\times 2 &= \\color{red}{0}.4 \\rightarrow \\color{red}{0} \\\\\n",
    "0.4 \\times 2 &= \\color{red}{0}.8 \\rightarrow \\color{red}{0} \\\\ \n",
    "0.8 \\times 2 &= \\color{red}{1}.6 \\rightarrow \\color{red}{1} \\\\\n",
    "0.6 \\times 2 &= \\color{red}{1}.2 \\rightarrow \\color{red}{1} \\\\\n",
    "0.2 \\times 2 &= \\color{red}{0}.4 \\rightarrow \\color{red}{0} \\\\\n",
    "0.4 \\times 2 &= \\color{red}{0}.8 \\rightarrow \\color{red}{0} \\\\ \n",
    "&\\text{this will now continue to repeat in the same pattern.}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Thus, we see that\n",
    "$$\n",
    "\\begin{align*}\n",
    "0.1 &= 0\\times 2^{-1} + 0\\times 2^{-2} + 0\\times 2^{-3} + 1\\times 2^{-4} + 1\\times 2^{-5} \\\\\n",
    "    &+ 0\\times 2^{-6} + 0\\times 2^{-7} + 0\\times 2^{-8} + 1\\times 2^{-9} + 1 \\times 2^{-10} \\\\\n",
    "    &+ \\text{pattern repeats}.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Then,\n",
    "$$\n",
    "\\begin{align*}\n",
    "3.1 &= 1\\times 2^1 + 1 \\times 2^{0} + 0\\times 2^{-1} + 0\\times 2^{-2} + 0\\times 2^{-3} + 1\\times 2^{-4} + 1\\times 2^{-5} + \\cdots \\\\\n",
    "&= +(1+f)2^{1}, \n",
    "\\end{align*}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "f = 1 \\times 2^{-1} + 0\\times 2^{-2} + 0\\times 2^{-3} + 0\\times 2^{-4} + 1\\times 2^{-5} + 1\\times 2^{-6} + \\cdots.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note that 3.1 does not have a finite binary expansion. Thus, we can not compute 3.1 exactly using its binary representation in Julia. However, we can at least perform a saninty check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.09375"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = [1,0,0,0,1,1]; # some of the coefficients of f\n",
    "p = -1:-1:-6; # some of the relevant powers of 2 in f\n",
    "t = 2.0.^p; # raise 2 to the relevant powers\n",
    "f = sum(c.*t); # compute partial f\n",
    "x = (1 + f)*2.0^1 # compute partial x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Carrying out our expansion further will get us closer to 3.1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.096774193548299"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = [1,0,0,0,1,1,0,0,0,1,1,0,0,0,1,1,0,0,0,1,1,0,0,0,1,1,0,0,0,1,1,0,0,0,1,1,0,0,0,1,1]; # some of the coefficients of f\n",
    "p = -1:-1:-41; # some of the relevant powers of 2 in f\n",
    "t = 2.0.^p; # raise 2 to the relevant powers\n",
    "f = sum(c.*t); # compute partial f\n",
    "x = (1 + f)*2.0^1 # compute partial x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's compute the error and accurate digits between 3.1 and our truncated binary expansion of 3.1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute error 0.0032258064517010077\n",
      "Relative error 0.0010405827263551637\n",
      "Accurate digits 2.9827233876566837\n"
     ]
    }
   ],
   "source": [
    "abs_err = abs(3.1 - x);\n",
    "rel_err = abs_err/abs(3.1);\n",
    "acc_dig = -log10(rel_err);\n",
    "println(\"Absolute error \", abs_err)\n",
    "println(\"Relative error \", rel_err)\n",
    "println(\"Accurate digits \", acc_dig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Take a second to think about why our method of \"repeated multiplication by 2\" works to find the binary expansion of the fractional part of a number. \n",
    "\n",
    "Here is the essential idea: We are assuming that\n",
    "$$\n",
    "0.1 = a_{1}2^{-1} + a_{2}2^{-2} + a_{3}2^{-3} + \\cdots, \n",
    "$$\n",
    "for some unique values for the coefficients $a_{1},a_{2},\\ldots$, with each one taking a value of either 0 or 1. Then multiplying by 2 gives:\n",
    "$$\n",
    "2\\times 0.1 = a_{1} + a_{2}2^{-1} + a_{3}2^{-2} + \\cdots,\n",
    "$$\n",
    "and this allows us to determine $a_{1}$. Multiplying by 2 again will allow us to determine $a_{2}$ and so on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now we have seen that for any $x\\in \\mathbb{R}$, we may write $x=\\pm(1+f)2^{N}$, where $N$ is an integer (*i.e.*, an element of $\\mathbb{Z}$), and $f=\\sum_{k=1}^{\\infty}a_{k}2^{-k}$. In the next section, we will discretize $\\mathbb{R}$ by *truncating* the binary expansion of real numbers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Floating Point and Finite Precision Numbers\n",
    "\n",
    "For a nonzero real number $x\\in \\mathbb{R}$, we have seen that\n",
    "$$\n",
    "x = \\pm\\left(1 + \\sum_{k=1}^{\\color{red}{\\infty}}a_{k}2^{-k} \\right)2^{\\color{red}{N}}, \\ \\ N\\in \\mathbb{Z}, \\ \\ a_{k}\\in\\{0,1\\}.\n",
    "$$\n",
    "Then we define $\\text{fl}(x)$ to be \"the closest value\" to $x$ that satisfies  \n",
    "$$\n",
    "\\text{fl}(x) = \\pm\\left(1 + \\sum_{k=1}^{\\color{red}{d}}a_{k}2^{-k} \\right)2^{\\color{red}{E}}, \\ \\ \\text{for some } E\\in \\{-N_{-},-N_{-}+1,\\ldots,-1,0,1,\\ldots,N_{+}\\}, \\ \\ a_{k}\\in\\{0,1\\},\n",
    "$$\n",
    "where $d$, $N_{-}$, and $N_{+}$ are **fixed positive integers**. The positive integer $d$ determines the number of significant binary digits. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example, if $d=2$, $N_{-}=1$, and $N_{+}=2$, then define the set\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbb{P}_{\\text{example}} &= \\left\\{\\pm\\left(1 + \\sum_{k=1}^{\\color{red}{2}}a_{k}2^{-k} \\right)2^{\\color{red}{E}} :\\ a_{k}\\in\\{0,1\\},\\ \\ E \\in \\{-1,0,1,2\\}\\right\\} \\\\\n",
    "&= \\pm\\left\\{\\frac{1}{2},\\frac{5}{8},\\frac{3}{4},\\frac{7}{8},1,\\frac{5}{4},\\frac{3}{2},\\frac{7}{4},2,\\frac{5}{2},3,\\frac{7}{2},4,5,6,7\\right\\}. \n",
    "\\end{align*}\n",
    "$$\n",
    "(We leave it as a homework exercise for you to show that the last equality is true.)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In this case rounding real numbers to values in $\\mathbb{P}_{\\text{example}}$, we would have, for example, \n",
    "$$\n",
    "\\begin{align*}\n",
    "x &= 2 \\Rightarrow \\text{fl}(x) = 2 = +(1 + 0\\times 2^{-1} + 0\\times 2^{-2})2^1, \\\\\n",
    "x &= 0.5 \\Rightarrow \\text{fl}(x) = \\frac{1}{2} = +(1+0\\times 2^{-1} + 0\\times 2^{-2})2^{-1}, \\\\\n",
    "x &= 1.6 \\Rightarrow \\text{fl}(x) = \\frac{3}{2} = +(1 + 1\\times 2^{-1} + 0\\times 2^{-2})2^0, \\\\\n",
    "x &= 1.7 \\Rightarrow \\text{fl}(x) = \\frac{7}{4} = +(1 + 1\\times 2^{-1} + 1\\times 2^{-2})2^0, \\\\\n",
    "x &= 4.2 \\Rightarrow \\text{fl}(x) = 4 = +(1 + 0\\times 2^{-1} + 0 \\times 2^{-2})2^2, \\\\\n",
    "x &= 4.6 \\Rightarrow \\text{fl}(x) = 5 = +(1 + 0\\times 2^{-1} + 1 \\times 2^{-2})2^2. \n",
    "\\end{align*}\n",
    "$$\n",
    "As homework, you should compute the errors and accurate digit values for each of the previous numbers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You may wonder, what would happen to a value such as $x=0.04$, which is a lot smaller than the smallest positive number in $\\mathbb{P}_{\\text{example}}$, or $x=10$, which is a lot larger than the largest positive value in $\\mathbb{P}_{\\text{example}}$.  This is an excellent question. We will add some additional values to the floating point numbers in order to handle such situations. For a particular choice of positive integers $d$, $N_{-}$, and $N_{+}$, we call the set\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbb{P} &= \\left\\{\\pm\\left(1 + \\sum_{k=1}^{\\color{red}{d}}a_{k}2^{-k} \\right)2^{\\color{red}{E}} :\\ a_{k}\\in\\{0,1\\},\\ \\ E \\in \\{-N_{-},\\ldots,N_{+}\\}\\right\\}, \n",
    "\\end{align*}\n",
    "$$\n",
    "a set of **floating point numbers**. Notice that we can denote an element $p \\in \\mathbb{P}$ by $p=\\pm(1+f)2^E$, where $f = \\sum_{k=1}^{d}a_{k}2^{-k}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Given a set of floating point numbers $\\mathbb{P}$, we define the **finite precision values** to be elements of the set \n",
    "$$\n",
    "\\text{finite precision values} = \\mathbb{P} \\cup \\{0,\\pm\\text{Inf},\\text{NaN}\\},\n",
    "$$\n",
    "where $0$ is zero and $\\pm\\text{Inf},\\text{NaN}$ are symbols which will be explained shortly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Commonly, in practical implementations, the standard choice for $d$, $N_{-}$, and $N_{+}$ is the so-called [**IEEE-754 standard**](https://en.wikipedia.org/wiki/IEEE_754) where $d=52$, $N_{-}=1022$, and $N_{+}=1023$. The symbol $\\text{Inf}$ is a value greater than any element of $\\mathbb{P}$, and  $-\\text{Inf}$ is a value less than any element of $\\mathbb{P}$. The symbol $\\text{NaN}$ (which stands for \"not a number\") is used to represent indeterminant forms such as $\\frac{0}{0}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Machine Precision\n",
    "\n",
    "From the definition of $\\mathbb{P}$, observe the following:\n",
    "\n",
    "1. We have $1+f \\in [1, 2)$, and this implies that for each $E$, $(1+f)2^{E} \\in [2^{E}, 2^{E+1})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "2. The smallest number of $\\mathbb{P}$ that is greater than $1$ is $1 + 2^{-d}$. We define **machine epsilon** to be $\\epsilon_{\\text{mach}} = 2^{-d}$.  (Note that machine epsilon is **not** the smallest positive floating point number, that value is $2^{-N_{-}}$, while the largest floating point number is just under $2^{N_{+} + 1}$). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "3. For each exponent $E\\in \\{-N_{-},-N_{-}+1,\\ldots,-1,0,1,\\ldots,N_{+}\\}$, there are $2^{d}$ evenly spaced floating point values in $[2^E,2^{E+1})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "4. For each exponent $E\\in \\{-N_{-},-N_{-}+1,\\ldots,-1,0,1,\\ldots,N_{+}\\}$, the distance between consecutive floating point numbers in $[2^E,2^{E+1})$ is $\\Delta = \\frac{2^{E+1} - 2^E}{2^d} = 2^{E-d}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In our example case where $d=2$, $N_{-}=1$, and $N_{+}=2$ we have that $\\epsilon_{\\text{mach}} = 2^{-2} = \\frac{1}{4}$ and hence $1+\\epsilon_{\\text{mach}} = \\frac{5}{4}$. However, the smallest positive value of $\\mathbb{P}_{\\text{example}}$ is $\\frac{1}{2}$. \n",
    "\n",
    "In IEEE 754 standard, $\\epsilon_{\\text{mach}} = 2^{-52}$ which can be accessed in Julia as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.220446049250313e-16"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps(Float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Compare that with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.220446049250313e-16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.0^-52"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Furthermore, we have the following estimates for the smallest and largest positive floating point values in Julia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2250738585072014e-308"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.0^-1022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6853373139334212e308"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1.0 + 2.0^-1 + 2.0^-2 + 2.0^-3)*2.0^1023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Notice what happens if we try to double our largest floating point number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inf"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.0^1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This produces a so-called **overflow**. There is also a phenomenon called **underflow** where a positive floating point number \n",
    "is rounded to zero. Finally, examine the following result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0/0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "These last examples helo to explain the meaning of the symbols $\\pm\\text{Inf}$ and $\\text{NaN}$ that were mentioned previously. \n",
    "\n",
    "\n",
    "You should understand and memorize the following important result: \n",
    "> **Theorem:** Let $x$ be a positive real number that lies in $[2^{E},2^{E+1})$ for some choice of exponent $E$ . Then\n",
    "$$\n",
    "|\\text{fl}(x) - x| \\leq \\frac{1}{2}2^{E-d}\n",
    "$$\n",
    "> and\n",
    "$$\n",
    "\\frac{|\\text{fl}(x) - x|}{|x|} \\leq \\frac{\\frac{1}{2}2^{E-d}}{2^{E}} \\leq \\frac{1}{2}\\epsilon_{\\text{mach}}. \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Floating Point Arithmetic\n",
    "\n",
    "On a machine, *i.e.*, a computer arithmetic is performed on floating point numbers and returns a finite precision value. Moving forward, our assumption will be that there is a set of floating point operations such as addition, multiplication, etc. that are analogous to the abstract arithmetic operations on real numbers. Furthermore, we will suppose that each floating point operation is carried out such that the resulting relative error is bounded by machine epsilon, $\\epsilon_{\\text{mach}}$. For example, if $\\bigoplus$ is used to denote floating point addition and if $x,y\\in \\mathbb{P}$ then we have\n",
    "$$\n",
    "\\frac{|(x\\bigoplus y) - (x+y)|}{|x+y|} \\leq \\epsilon_{\\text{mach}}. \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Finite Precision as Perturbations\n",
    "\n",
    "We may view finite precision numbers and arithmetic as perturbations to exact real numbers and exact real number arithmetic. That is, if $x \\in \\mathbb{R}$, we may consider \n",
    "$$\n",
    "\\text{fl}(x) = x(1 + \\delta), \\text{where } |\\delta| \\leq \\frac{\\epsilon_{\\text{mach}}}{2}, \n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{fl}(\\text{fl}(x) \\pm \\text{fl}(y)) &= \\text{fl}(x) \\pm \\text{fl}(y)(1 + \\delta_{1}), \\\\\n",
    "\\text{fl}(\\text{fl}(x) \\times \\text{fl}(y)) &= \\text{fl}(x) \\times \\text{fl}(y)(1 + \\delta_{2}), \\\\\n",
    "\\text{fl}(\\text{fl}(x) \\div \\text{fl}(y)) &= \\text{fl}(x) \\div \\text{fl}(y)(1 + \\delta_{3}), \n",
    "\\end{align*}\n",
    "$$\n",
    "where each of $\\delta_{1}$, $\\delta_{2}$, and $\\delta_{3}$ are bounded by $\\epsilon_{\\text{mach}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here is the important point, since any time we solve a problem on a computer we are introducing a (typically small) perturbation, it is important to understand how sensitive our solution or method of solution is to small perturbations. This is addressed by the notions of stability and conditioning which we will take up in the next set of notes."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
